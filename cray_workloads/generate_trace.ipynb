{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = Path('/home/bj2/faro/experiments/top9_twitter_1_1600_avgproc_min_int5m_reduced_6hr_augmented/input.json').read_text().splitlines()\n",
    "\n",
    "dataset = defaultdict(list)\n",
    "\n",
    "for line in lines:\n",
    "    obj = json.loads(line)\n",
    "    for cluster_name, v in obj[\"counts\"].items():\n",
    "        dataset[cluster_name].append(v[\"classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = {}\n",
    "\n",
    "for cluster_name, values in dataset.items():\n",
    "    tss = []\n",
    "    data = []\n",
    "    for i, v in enumerate(values):\n",
    "        new_dist = np.random.poisson(lam=v/60, size=60)\n",
    "        # print(new_dist)\n",
    "        diff = v - new_dist.sum()\n",
    "        # print(diff)\n",
    "        if diff < 0:\n",
    "            for idx in np.random.choice(60, -diff):\n",
    "                new_dist[idx] -= 1\n",
    "        elif diff > 0:\n",
    "            for idx in np.random.choice(60, diff):\n",
    "                new_dist[idx] += 1\n",
    "        # print(new_dist)\n",
    "        assert new_dist.sum() == v\n",
    "        ts = (60 * i + np.arange(60)) * 1e3\n",
    "        tss.extend(ts.astype(int))\n",
    "        data.extend(new_dist.astype(float))\n",
    "    df = pd.DataFrame({\"timestamp\": tss, \"data\": data})\n",
    "    new_dataset[cluster_name] = df\n",
    "    assert df[\"data\"].sum() == np.sum(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_name, df in new_dataset.items():\n",
    "    df.to_csv(f\"./traces/{cluster_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cilantro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
